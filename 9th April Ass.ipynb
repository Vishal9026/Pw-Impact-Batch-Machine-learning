{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec99e25-8b3d-4396-bbc5-7449dd4ebad0",
   "metadata": {},
   "source": [
    "# Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61132208-9f10-4d43-9cb7-4d61a2ef8b00",
   "metadata": {},
   "source": [
    "Mathematically, Bayes' theorem is expressed as follows:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) represents the probability of event A occurring given that event B has occurred.\n",
    "P(B|A) is the probability of event B occurring given that event A has occurred.\n",
    "P(A) and P(B) are the probabilities of events A and B occurring independently of each other.\n",
    "In simpler terms, Bayes' theorem allows us to calculate the probability of an event A happening given some evidence or observation B. It takes into account the prior probability of A (P(A)), the likelihood of observing B given that A is true (P(B|A)), and the overall probability of observing B (P(B)).\n",
    "\n",
    "Bayes' theorem is widely used in various fields, including statistics, machine learning, artificial intelligence, and decision-making. It provides a principled way of updating beliefs and making predictions based on both prior knowledge and new information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40bef7-c8da-4b69-9e86-690e1a642972",
   "metadata": {},
   "source": [
    "# Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a75376-c60a-4907-ab6f-007350d3b88a",
   "metadata": {},
   "source": [
    "Mathematically, Bayes' theorem is expressed as follows:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c43ba-263e-4af7-b800-fb836ceed074",
   "metadata": {},
   "source": [
    "# Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01977ee8-5b59-4a9e-8d97-e1db4ce3f6e2",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in practice for various applications, including but not limited to:\n",
    "\n",
    "1-Bayesian Inference: It is used to update probabilities and make predictions based on observed data. Bayesian inference allows for the incorporation of prior knowledge and evidence to obtain more accurate estimates.\n",
    "\n",
    "2-Medical Diagnosis: Bayes' theorem is used to calculate the probability of a patient having a particular disease based on observed symptoms and prior knowledge about the disease's prevalence and symptom associations.\n",
    "\n",
    "3-Spam Filtering: Bayes' theorem is employed in spam filters to classify emails as spam or non-spam. It uses prior knowledge of spam and non-spam emails and the presence of specific words or patterns in an email to calculate the probability of it being spam.\n",
    "\n",
    "4-Machine Learning: Bayesian methods, such as Naive Bayes classifiers, leverage Bayes' theorem to estimate the probability of a class label given a set of features. They are widely used in text classification, sentiment analysis, and other machine learning tasks.\n",
    "\n",
    "5-Risk Assessment: Bayes' theorem helps in assessing risks and making informed decisions based on prior knowledge and observed evidence. It is used in fields like finance, insurance, and quality control to quantify risks and adjust probabilities based on new information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f9ec7-cc58-4a24-b7dd-cb35a79687f6",
   "metadata": {},
   "source": [
    "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e93e217-68b3-4347-9f1b-a78ce3e9ec35",
   "metadata": {},
   "source": [
    "When choosing a type of Naive Bayes classifier for a specific problem, the decision depends on the nature of the problem and the characteristics of the data. Here's a short answer on how to choose:\n",
    "\n",
    "1.Multinomial Naive Bayes: This classifier is commonly used for text classification problems where the features represent word frequencies or occurrence counts. It assumes that features have discrete integer values, making it suitable for problems like sentiment analysis, spam filtering, or document categorization.\n",
    "\n",
    "2.Gaussian Naive Bayes: This classifier is appropriate when dealing with continuous features that follow a Gaussian (normal) distribution. It assumes that the features are continuous and independent, making it suitable for problems involving real-valued data. Gaussian Naive Bayes can be used in scenarios like predicting the likelihood of an event based on numerical features.\n",
    "\n",
    "3.Bernoulli Naive Bayes: This classifier is suitable when the features are binary or Boolean variables, indicating the presence or absence of specific attributes. It assumes that features are independent and follow a Bernoulli distribution. Bernoulli Naive Bayes is commonly used in problems like text classification, spam filtering, or sentiment analysis, where features represent the presence or absence of certain words or features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd97a11-8867-49ab-b293-256fb62755a0",
   "metadata": {},
   "source": [
    "# Q6. Assignment:\n",
    "# You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "# Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "# Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "# A 3 3 4 4 3 3 3\n",
    "# B 2 2 1 2 2 2 3\n",
    "# Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614cd57-4a8d-49f9-8145-24d66e92d504",
   "metadata": {},
   "source": [
    "To predict the class using Naive Bayes, we need to calculate the conditional probabilities for each class based on the given feature values.\n",
    "\n",
    "First, we calculate the conditional probabilities for Class A:\n",
    "\n",
    "P(X1 = 3 | A) = 4/13\n",
    "P(X2 = 4 | A) = 3/13\n",
    "P(A) = 7/20 (assuming equal prior probabilities for each class)\n",
    "\n",
    "Next, we calculate the conditional probabilities for Class B:\n",
    "\n",
    "P(X1 = 3 | B) = 1/7\n",
    "P(X2 = 4 | B) = 3/7\n",
    "P(B) = 7/20 (assuming equal prior probabilities for each class)\n",
    "\n",
    "Now, let's calculate the posterior probabilities using Bayes' theorem:\n",
    "\n",
    "P(A | X1 = 3, X2 = 4) = (P(X1 = 3 | A) * P(X2 = 4 | A) * P(A)) / P(X1 = 3, X2 = 4)\n",
    "P(B | X1 = 3, X2 = 4) = (P(X1 = 3 | B) * P(X2 = 4 | B) * P(B)) / P(X1 = 3, X2 = 4)\n",
    "\n",
    "Since the denominator P(X1 = 3, X2 = 4) is the same for both classes, we can compare the numerators directly:\n",
    "\n",
    "Numerators:\n",
    "- For Class A: (4/13) * (3/13) * (7/20) = 84/439\n",
    "- For Class B: (1/7) * (3/7) * (7/20) = 3/140\n",
    "\n",
    "Comparing the numerators, we find that the numerator for Class A (84/439) is greater than the numerator for Class B (3/140). Therefore, Naive Bayes would predict the new instance to belong to Class A.\n",
    "\n",
    "Thus, Naive Bayes would classify the new instance with features X1 = 3 and X2 = 4 as belonging to Class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bcf4f4-1c6d-4d85-b735-2ffabee695f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1459a4-a415-4228-ae0c-14155500e8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0f6c5-1853-4c0b-9f0e-02ab1f7e054b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b849ce3-2794-4e0d-89a6-e5a3c95bbfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
